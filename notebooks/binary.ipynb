{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d46f5412-ecfd-4914-9d15-4d8e29989f26",
   "metadata": {},
   "source": [
    "# Loading the Census Income (KDD) Dataset\n",
    "The `.names` file is a convention used by the UCI Machine Learning Repository to provide essential metadata about the datasets they host."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e8e5a91d-168e-423b-8ad0-b9e82868bb04",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "# Importing necessary objects for data manipulation and analysis.\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.metrics import classification_report, accuracy_score, balanced_accuracy_score, roc_auc_score, precision_recall_curve, auc, precision_score, recall_score, make_scorer\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.preprocessing import TargetEncoder, OneHotEncoder, OrdinalEncoder, LabelEncoder, StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from imblearn.under_sampling import ClusterCentroids\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.combine import SMOTEENN\n",
    "from imblearn.pipeline import Pipeline as ImbPipeline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4a54b174-efd4-4ca5-a511-5ada4c52a167",
   "metadata": {},
   "outputs": [],
   "source": [
    "# It's easier to extract useful infomration about column names and distinct values from the .names file then to write it out.\n",
    "def parse_names():\n",
    "    \"\"\"\n",
    "    Parses the .names file from the Census-Income (KDD) dataset to extract information about the variables.\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary where each key is a variable name, and the value describes the variable as either 'continuous' or 'nominal'.\n",
    "              For nominal variables, it includes the distinct values found in the dataset.\n",
    "    \"\"\"\n",
    "\n",
    "    result = {}\n",
    "\n",
    "    # The .names file doesn't follow a strict format.\n",
    "    with open('../data/census/census-income.names', 'r') as file:\n",
    "        text = file.read()\n",
    "\n",
    "    # Just take lines that define attributes.\n",
    "    etch = list(filter(lambda x: not (x.startswith('|') or x.startswith('-') or x.strip() == ''), text.splitlines()))\n",
    "    for line in etch:\n",
    "        key, value = map(lambda x: x.rstrip(\".\").strip(), line.split(':'))\n",
    "\n",
    "        if value == \"continuous\":\n",
    "            result[key] = {\"type\": \"continuous\"}\n",
    "        else:\n",
    "            values = list(map(lambda x: x.strip(), value.split(\",\")))\n",
    "\n",
    "            # Try converting to an integer.\n",
    "            try:\n",
    "                values = list(map(int, values))\n",
    "            except:\n",
    "                pass\n",
    "            result[key] = {\"type\": \"nominal\", \"values\": values}\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c4401fdd-9c51-4576-ba18-11a6f92cb615",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function parse_names in module __main__:\n",
      "\n",
      "parse_names()\n",
      "    Parses the .names file from the Census-Income (KDD) dataset to extract information about the variables.\n",
      "    \n",
      "    Returns:\n",
      "        dict: A dictionary where each key is a variable name, and the value describes the variable as either 'continuous' or 'nominal'.\n",
      "              For nominal variables, it includes the distinct values found in the dataset.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Invoke the built-in help system.\n",
    "help(parse_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "546ef9db-c336-44a3-bacb-ec62a4ce2a4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A 'codebook' is just something to help with understanding a dataset.\n",
    "codebook = parse_names()\n",
    "\n",
    "# The target is the last column in the dataset.\n",
    "column_names = list(codebook.keys()) + [\"income\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8338ae15-203e-48e8-b87e-ded08743915b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(199523, 42)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = pd.read_csv('../data/census/census-income.data', names=column_names, index_col=False)\n",
    "train_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "89f34925-f411-43a6-b92c-9e9cb5ef33ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(99762, 42)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df = pd.read_csv('../data/census/census-income.test', names=column_names, index_col=False)\n",
    "test_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "792c5bb2-c13e-4fab-abb5-f0934d02d043",
   "metadata": {},
   "source": [
    "# Exploring the Dataset\n",
    "\n",
    "Pandas preserves spaces that are in the dataset, these spaces aren't important and can be removed while exploring.\n",
    "\n",
    "Missing values show up in the dataset as '?'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8297f75b-3b64-4023-b2e0-4a5af2a3635c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 199523 entries, 0 to 199522\n",
      "Data columns (total 42 columns):\n",
      " #   Column                                      Non-Null Count   Dtype  \n",
      "---  ------                                      --------------   -----  \n",
      " 0   age                                         199523 non-null  int64  \n",
      " 1   class of worker                             199523 non-null  object \n",
      " 2   detailed industry recode                    199523 non-null  int64  \n",
      " 3   detailed occupation recode                  199523 non-null  int64  \n",
      " 4   education                                   199523 non-null  object \n",
      " 5   wage per hour                               199523 non-null  int64  \n",
      " 6   enroll in edu inst last wk                  199523 non-null  object \n",
      " 7   marital stat                                199523 non-null  object \n",
      " 8   major industry code                         199523 non-null  object \n",
      " 9   major occupation code                       199523 non-null  object \n",
      " 10  race                                        199523 non-null  object \n",
      " 11  hispanic origin                             199523 non-null  object \n",
      " 12  sex                                         199523 non-null  object \n",
      " 13  member of a labor union                     199523 non-null  object \n",
      " 14  reason for unemployment                     199523 non-null  object \n",
      " 15  full or part time employment stat           199523 non-null  object \n",
      " 16  capital gains                               199523 non-null  int64  \n",
      " 17  capital losses                              199523 non-null  int64  \n",
      " 18  dividends from stocks                       199523 non-null  int64  \n",
      " 19  tax filer stat                              199523 non-null  object \n",
      " 20  region of previous residence                199523 non-null  object \n",
      " 21  state of previous residence                 198815 non-null  object \n",
      " 22  detailed household and family stat          199523 non-null  object \n",
      " 23  detailed household summary in household     199523 non-null  object \n",
      " 24  instance weight                             199523 non-null  float64\n",
      " 25  migration code-change in msa                99827 non-null   object \n",
      " 26  migration code-change in reg                99827 non-null   object \n",
      " 27  migration code-move within reg              99827 non-null   object \n",
      " 28  live in this house 1 year ago               199523 non-null  object \n",
      " 29  migration prev res in sunbelt               99827 non-null   object \n",
      " 30  num persons worked for employer             199523 non-null  int64  \n",
      " 31  family members under 18                     199523 non-null  object \n",
      " 32  country of birth father                     192810 non-null  object \n",
      " 33  country of birth mother                     193404 non-null  object \n",
      " 34  country of birth self                       196130 non-null  object \n",
      " 35  citizenship                                 199523 non-null  object \n",
      " 36  own business or self employed               199523 non-null  int64  \n",
      " 37  fill inc questionnaire for veteran's admin  199523 non-null  object \n",
      " 38  veterans benefits                           199523 non-null  int64  \n",
      " 39  weeks worked in year                        199523 non-null  int64  \n",
      " 40  year                                        199523 non-null  int64  \n",
      " 41  income                                      199523 non-null  object \n",
      "dtypes: float64(1), int64(12), object(29)\n",
      "memory usage: 63.9+ MB\n"
     ]
    }
   ],
   "source": [
    "df = train_df.apply(lambda x: x.str.strip() if x.dtype == \"object\" else x)\n",
    "\n",
    "# You can check the column names, missing values, and data type.\n",
    "df.replace('?', None).info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8b136352-621c-404b-857e-f8034bafcf36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "state of previous residence: {'?'}\n",
      "migration code-change in msa: {'?'}\n",
      "migration code-change in reg: {'?'}\n",
      "migration code-move within reg: {'?'}\n",
      "migration prev res in sunbelt: {'?'}\n",
      "country of birth father: {'?'}\n",
      "country of birth mother: {'?'}\n",
      "country of birth self: {'?'}\n"
     ]
    }
   ],
   "source": [
    "# Find values that aren't listed in .names.\n",
    "def display_unexpected_values(df, codebook):\n",
    "    for key, value in codebook.items():\n",
    "        if value[\"type\"] == \"continuous\":\n",
    "            continue\n",
    "\n",
    "        expected_values = set(value[\"values\"])\n",
    "        actual_values = set(df[key].unique())\n",
    "        unexpected_values = actual_values - expected_values\n",
    "\n",
    "        if unexpected_values:\n",
    "            print(f\"{key}: {unexpected_values}\")\n",
    "\n",
    "# The .names file doens't talk about '?' as a posible value for the nominals which is why it's showing up.\n",
    "display_unexpected_values(df, codebook)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "948e062b-752d-4881-96d8-906c88d536c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "state of previous residence: 0.35% missing\n",
      "migration code-change in msa: 49.97% missing\n",
      "migration code-change in reg: 49.97% missing\n",
      "migration code-move within reg: 49.97% missing\n",
      "migration prev res in sunbelt: 49.97% missing\n",
      "country of birth father: 3.36% missing\n",
      "country of birth mother: 3.07% missing\n",
      "country of birth self: 1.70% missing\n"
     ]
    }
   ],
   "source": [
    "def calculate_missingness(df):\n",
    "    for column in df.select_dtypes(include=['object']):\n",
    "        missing_count = (df[column].str.strip() == \"?\").sum()\n",
    "        total_count = len(df[column])\n",
    "        missing_percentage = (missing_count / total_count) * 100\n",
    "        if missing_count > 0:\n",
    "            print(f\"{column}: {missing_percentage:.2f}% missing\")\n",
    "\n",
    "# Computes the percentage of missing values represented by '?' for string columns in the dataset.\n",
    "calculate_missingness(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "096678e2-345f-4810-b089-5da1ba8cc125",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>min</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>age</th>\n",
       "      <td>0.0</td>\n",
       "      <td>90.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wage per hour</th>\n",
       "      <td>0.0</td>\n",
       "      <td>9999.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>capital gains</th>\n",
       "      <td>0.0</td>\n",
       "      <td>99999.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>capital losses</th>\n",
       "      <td>0.0</td>\n",
       "      <td>4608.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dividends from stocks</th>\n",
       "      <td>0.0</td>\n",
       "      <td>99999.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>num persons worked for employer</th>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weeks worked in year</th>\n",
       "      <td>0.0</td>\n",
       "      <td>52.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 min      max\n",
       "age                              0.0     90.0\n",
       "wage per hour                    0.0   9999.0\n",
       "capital gains                    0.0  99999.0\n",
       "capital losses                   0.0   4608.0\n",
       "dividends from stocks            0.0  99999.0\n",
       "num persons worked for employer  0.0      6.0\n",
       "weeks worked in year             0.0     52.0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's only look at columns that actually represent numeric data.\n",
    "continuous = list(filter(lambda x: codebook[x][\"type\"] == \"continuous\" and x != \"instance weight\", codebook.keys()))\n",
    "\n",
    "# Some of these values might be capped.\n",
    "df[continuous].describe().T[[\"min\", \"max\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fda99181-7b28-4347-937d-14feb178d9a2",
   "metadata": {},
   "source": [
    "# Binary Classification Task\n",
    "\n",
    "The **Census-Income (KDD)** dataset is derived from the **1994 and 1995 Current Population Surveys (CPS)** conducted by the U.S. Census Bureau.\n",
    "\n",
    "It includes **199,523 training instances** and **99,762 test instances**.\n",
    "\n",
    "The goal is to predict the income level based on the data provided in each row. Incomes have been binned at the $50K level to create a binary classification problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ae2ba05e-7a42-4323-b030-516d6750633c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of categorical columns.\n",
    "nominal = list(filter(lambda x: codebook[x][\"type\"] == \"nominal\", codebook.keys()))\n",
    "\n",
    "# List of numerical columns.\n",
    "continuous = list(filter(lambda x: codebook[x][\"type\"] == \"continuous\", codebook.keys()))\n",
    "\n",
    "# Ignore 'instance weight'.\n",
    "continuous.remove(\"instance weight\")\n",
    "\n",
    "# The 'instance weight' column happens to make the RandomForestClassifier more accurate.\n",
    "# The dataset feels like a distribution problem to me instead of a prediction problem so I'd tend to use any columns that help with modeling the distribution.\n",
    "# The .names file suggested to not use it... I don't even think there are real realtionships to learn in this data though.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33b4158a-4f38-458a-a982-af99d8719d7b",
   "metadata": {},
   "source": [
    "## Encoding Categorical Features\n",
    "\n",
    "The way features are encoded for this dataset doesn't seem to make much difference in the modeling.\n",
    "\n",
    "Most columns do not have a natural ordering and should use One-Hot encoding for best performance!\n",
    "\n",
    "The `OneHotEncoder` makes things substantially slower though, and I don't want to suffer through that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2f8bdc3a-9d26-4b20-ba5c-ee1f3c15591f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def value_distribution(series):\n",
    "    # Get value counts.\n",
    "    value_counts = series.value_counts()\n",
    "    \n",
    "    # Calculate percentages.\n",
    "    percentages = (value_counts / len(series)) * 100\n",
    "\n",
    "    return pd.DataFrame({'count': value_counts, 'percentage': percentages})\n",
    "\n",
    "# Values for each category column seem to have plenty of examples.\n",
    "# for column in nominal:\n",
    "#     display(value_distribution(df[column]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2505a6c-e31a-4b2a-8696-504d31cfbe02",
   "metadata": {},
   "source": [
    "### Encoding the Target\n",
    "The traget can be encoded using the `LabelEncoder`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9bff22ae-08da-4c91-9344-47440aca30f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([' - 50000.', ' 50000+.'], dtype=object)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_encoder = LabelEncoder()\n",
    "\n",
    "# Fit the encoder on training data.\n",
    "label_encoder.fit(train_df[\"income\"])\n",
    "\n",
    "# Transform the training and test data.\n",
    "y = label_encoder.transform(train_df[\"income\"])\n",
    "y_test = label_encoder.transform(test_df[\"income\"])\n",
    "\n",
    "# The unique values are sorted in lexicographical order.\n",
    "label_encoder.classes_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1db6f6b-b39b-44a5-8874-e383fa8977fb",
   "metadata": {},
   "source": [
    "### Encoding the Features\n",
    "The features can be encoded using `OrdinalEncoder` or `OneHotEncoder`.\n",
    "\n",
    "But, the `OneHotEncoder` creates a bunch of additional columns and a `TargetEncoder` performs well enough."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3c0cdbcd-d4d7-42ae-b7e6-98543c857800",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode categorical features.\n",
    "encoder = TargetEncoder()\n",
    "\n",
    "# Fit the encoder to the training data.\n",
    "encoder.fit(train_df[nominal], y)\n",
    "\n",
    "# Names for the encoded features.\n",
    "feature_names = encoder.get_feature_names_out(nominal)\n",
    "\n",
    "# Encode the training and test data.\n",
    "X = pd.concat([pd.DataFrame(encoder.transform(train_df[nominal]), columns=feature_names), train_df[continuous]], axis=1)\n",
    "X_test = pd.concat([pd.DataFrame(encoder.transform(test_df[nominal]), columns=feature_names), test_df[continuous]], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9597792d-52ae-4625-b1dd-83f1da41ac7d",
   "metadata": {},
   "source": [
    "## Scaling Features\n",
    "\n",
    "You don't need to scale the categorical columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d25d24a7-3977-4cf7-84d6-18a49e1ed775",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit a standard scaler to training data.\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X[continuous])\n",
    "\n",
    "# Transform the training data.\n",
    "X[continuous] = scaler.transform(X[continuous])\n",
    "\n",
    "# Transform the testing data.\n",
    "X_test[continuous] = scaler.transform(X_test[continuous])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54127eb7-3716-4ea0-9334-db98cb161153",
   "metadata": {},
   "source": [
    "## Cross Validation\n",
    "\n",
    "You could use cross validation to see how well the model performs for the given encodings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "aa12f05e-3d4d-4226-b0f6-a7e0ddd4585e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.95556948, 0.95554442, 0.95587019, 0.95434042, 0.95551824])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = RandomForestClassifier(random_state=42)\n",
    "cross_val_score(model, X, y, cv=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00f87a53-5723-4d54-81fb-fba359c2604d",
   "metadata": {},
   "source": [
    "## Dealing With Class Imbalance\n",
    "\n",
    "Resampling teaches the model to guess the minority class more frequently with worse precision."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a8fdc728-356d-434c-afa9-d668499e9571",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_class_imbalance(target):\n",
    "    class_0_count = np.count_nonzero(target == 0)\n",
    "    class_1_count = np.count_nonzero(target == 1)\n",
    "    total_count = len(target)\n",
    "\n",
    "    # Calculate the percentages.\n",
    "    class_0_percentage = (class_0_count / total_count) * 100\n",
    "    class_1_percentage = (class_1_count / total_count) * 100\n",
    "\n",
    "    print(f\"Class 0: {class_0_count} instances, {class_0_percentage}% of the total\")\n",
    "    print(f\"Class 1: {class_1_count} instances, {class_1_percentage}% of the total\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3e31a39e-dfc6-4627-ac72-e78a12bda9fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class 0: 93576 instances, 93.7992421964275% of the total\n",
      "Class 1: 6186 instances, 6.200757803572503% of the total\n"
     ]
    }
   ],
   "source": [
    "display_class_imbalance(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c45f815e-9a28-4d98-b9e7-ce353f53b7b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def balanced_accuracy_with_report(y_true, y_predication):\n",
    "    print(\"\\nClassification Report:\\n\", classification_report(y_true, y_predication))\n",
    "    return balanced_accuracy_score(y_true, y_predication)\n",
    "\n",
    "scorer = make_scorer(balanced_accuracy_with_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "705d3053-2d89-475f-a0ca-1a7d9a2daae4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_cross_val_score(X, y, model, sampler, cv=5, scoring='balanced_accuracy'):\n",
    "    # Create a pipeline with the provided sampler and model instances.\n",
    "    pipeline = ImbPipeline(steps=[('resample', sampler), ('model', model)])\n",
    "\n",
    "    # Time the cross-validation process.\n",
    "    start_time = time.time()\n",
    "    cv_scores = cross_val_score(pipeline, X, y, cv=cv, scoring=scorer)\n",
    "    end_time = time.time()\n",
    "\n",
    "    # Calculate the elapsed time.\n",
    "    elapsed_time = end_time - start_time\n",
    "    print(f\"Cross-validation with {model.__class__.__name__} and {sampler.__class__.__name__}: {elapsed_time:.2f} seconds\")\n",
    "\n",
    "    # Return the cross-validation scores.\n",
    "    return cv_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ad92d831-ad22-4ac1-b0ad-e56ce8802f79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.98      0.97     37429\n",
      "           1       0.63      0.51      0.56      2476\n",
      "\n",
      "    accuracy                           0.95     39905\n",
      "   macro avg       0.80      0.75      0.77     39905\n",
      "weighted avg       0.95      0.95      0.95     39905\n",
      "\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.98      0.97     37428\n",
      "           1       0.63      0.51      0.56      2477\n",
      "\n",
      "    accuracy                           0.95     39905\n",
      "   macro avg       0.80      0.74      0.77     39905\n",
      "weighted avg       0.95      0.95      0.95     39905\n",
      "\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.98      0.97     37428\n",
      "           1       0.64      0.51      0.57      2477\n",
      "\n",
      "    accuracy                           0.95     39905\n",
      "   macro avg       0.80      0.75      0.77     39905\n",
      "weighted avg       0.95      0.95      0.95     39905\n",
      "\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.98      0.97     37428\n",
      "           1       0.62      0.51      0.56      2476\n",
      "\n",
      "    accuracy                           0.95     39904\n",
      "   macro avg       0.79      0.74      0.77     39904\n",
      "weighted avg       0.95      0.95      0.95     39904\n",
      "\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.98      0.97     37428\n",
      "           1       0.62      0.49      0.55      2476\n",
      "\n",
      "    accuracy                           0.95     39904\n",
      "   macro avg       0.79      0.74      0.76     39904\n",
      "weighted avg       0.95      0.95      0.95     39904\n",
      "\n",
      "Cross-validation with RandomForestClassifier and RandomOverSampler: 85.62 seconds\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.74540666, 0.74344499, 0.74582426, 0.74290452, 0.7362508 ])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Random Oversampling 😂\n",
    "# ❌ 💥🤯🔥💣 😈 😈 😈 🐖 🐖 🐖\n",
    "time_cross_val_score(X, y, RandomForestClassifier(random_state=42), RandomOverSampler(random_state=42))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ced9c121-d270-4423-8e59-1203ff8d0f02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.85      0.92     37429\n",
      "           1       0.29      0.90      0.43      2476\n",
      "\n",
      "    accuracy                           0.85     39905\n",
      "   macro avg       0.64      0.88      0.68     39905\n",
      "weighted avg       0.95      0.85      0.89     39905\n",
      "\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.85      0.92     37428\n",
      "           1       0.29      0.89      0.43      2477\n",
      "\n",
      "    accuracy                           0.86     39905\n",
      "   macro avg       0.64      0.87      0.68     39905\n",
      "weighted avg       0.95      0.86      0.89     39905\n",
      "\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.85      0.92     37428\n",
      "           1       0.29      0.90      0.44      2477\n",
      "\n",
      "    accuracy                           0.85     39905\n",
      "   macro avg       0.64      0.88      0.68     39905\n",
      "weighted avg       0.95      0.85      0.89     39905\n",
      "\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.85      0.91     37428\n",
      "           1       0.28      0.89      0.43      2476\n",
      "\n",
      "    accuracy                           0.85     39904\n",
      "   macro avg       0.64      0.87      0.67     39904\n",
      "weighted avg       0.95      0.85      0.88     39904\n",
      "\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.85      0.92     37428\n",
      "           1       0.28      0.88      0.43      2476\n",
      "\n",
      "    accuracy                           0.85     39904\n",
      "   macro avg       0.64      0.87      0.67     39904\n",
      "weighted avg       0.95      0.85      0.89     39904\n",
      "\n",
      "Cross-validation with RandomForestClassifier and RandomUnderSampler: 6.71 seconds\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.87651981, 0.87133551, 0.87725017, 0.86843936, 0.86748714])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Random Undersampling\n",
    "time_cross_val_score(X, y, RandomForestClassifier(random_state=42), RandomUnderSampler(random_state=42))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "75c81de0-5dac-4a05-ad6a-a0cb71a236b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.47      0.63     37429\n",
      "           1       0.11      0.96      0.19      2476\n",
      "\n",
      "    accuracy                           0.50     39905\n",
      "   macro avg       0.55      0.71      0.41     39905\n",
      "weighted avg       0.94      0.50      0.61     39905\n",
      "\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.47      0.64     37428\n",
      "           1       0.11      0.96      0.19      2477\n",
      "\n",
      "    accuracy                           0.50     39905\n",
      "   macro avg       0.55      0.71      0.41     39905\n",
      "weighted avg       0.94      0.50      0.61     39905\n",
      "\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.46      0.63     37428\n",
      "           1       0.11      0.96      0.19      2477\n",
      "\n",
      "    accuracy                           0.50     39905\n",
      "   macro avg       0.55      0.71      0.41     39905\n",
      "weighted avg       0.94      0.50      0.61     39905\n",
      "\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.47      0.64     37428\n",
      "           1       0.11      0.96      0.19      2476\n",
      "\n",
      "    accuracy                           0.50     39904\n",
      "   macro avg       0.55      0.71      0.41     39904\n",
      "weighted avg       0.94      0.50      0.61     39904\n",
      "\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.47      0.64     37428\n",
      "           1       0.11      0.95      0.19      2476\n",
      "\n",
      "    accuracy                           0.50     39904\n",
      "   macro avg       0.55      0.71      0.42     39904\n",
      "weighted avg       0.94      0.50      0.61     39904\n",
      "\n",
      "Cross-validation with RandomForestClassifier and ClusterCentroids: 417.22 seconds\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.71224467, 0.71325221, 0.71456264, 0.71299588, 0.71304247])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cluster Centroids\n",
    "time_cross_val_score(X, y, RandomForestClassifier(random_state=42), ClusterCentroids(random_state=42))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "75f1c0ce-6d4c-45eb-af36-45381f8d17f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.98      0.97     37429\n",
      "           1       0.64      0.49      0.56      2476\n",
      "\n",
      "    accuracy                           0.95     39905\n",
      "   macro avg       0.80      0.74      0.76     39905\n",
      "weighted avg       0.95      0.95      0.95     39905\n",
      "\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.98      0.97     37428\n",
      "           1       0.63      0.49      0.55      2477\n",
      "\n",
      "    accuracy                           0.95     39905\n",
      "   macro avg       0.80      0.73      0.76     39905\n",
      "weighted avg       0.95      0.95      0.95     39905\n",
      "\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.98      0.97     37428\n",
      "           1       0.64      0.49      0.55      2477\n",
      "\n",
      "    accuracy                           0.95     39905\n",
      "   macro avg       0.80      0.74      0.76     39905\n",
      "weighted avg       0.95      0.95      0.95     39905\n",
      "\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.98      0.97     37428\n",
      "           1       0.62      0.47      0.54      2476\n",
      "\n",
      "    accuracy                           0.95     39904\n",
      "   macro avg       0.79      0.73      0.75     39904\n",
      "weighted avg       0.94      0.95      0.95     39904\n",
      "\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.98      0.97     37428\n",
      "           1       0.64      0.47      0.54      2476\n",
      "\n",
      "    accuracy                           0.95     39904\n",
      "   macro avg       0.80      0.73      0.76     39904\n",
      "weighted avg       0.95      0.95      0.95     39904\n",
      "\n",
      "Cross-validation with RandomForestClassifier and SMOTE: 161.22 seconds\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.73689228, 0.73344271, 0.73508281, 0.72737731, 0.72715579])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Synthetic Minority Oversampling Technique (SMOTE)\n",
    "time_cross_val_score(X, y, RandomForestClassifier(random_state=42), SMOTE(random_state=42))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "208a9887-2e44-4e0b-b8b5-6be95747d280",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.95      0.96     37429\n",
      "           1       0.47      0.71      0.57      2476\n",
      "\n",
      "    accuracy                           0.93     39905\n",
      "   macro avg       0.72      0.83      0.76     39905\n",
      "weighted avg       0.95      0.93      0.94     39905\n",
      "\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.95      0.96     37428\n",
      "           1       0.47      0.70      0.56      2477\n",
      "\n",
      "    accuracy                           0.93     39905\n",
      "   macro avg       0.72      0.83      0.76     39905\n",
      "weighted avg       0.95      0.93      0.94     39905\n",
      "\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.95      0.96     37428\n",
      "           1       0.47      0.69      0.56      2477\n",
      "\n",
      "    accuracy                           0.93     39905\n",
      "   macro avg       0.73      0.82      0.76     39905\n",
      "weighted avg       0.95      0.93      0.94     39905\n",
      "\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.95      0.96     37428\n",
      "           1       0.46      0.68      0.55      2476\n",
      "\n",
      "    accuracy                           0.93     39904\n",
      "   macro avg       0.72      0.82      0.76     39904\n",
      "weighted avg       0.95      0.93      0.94     39904\n",
      "\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.95      0.96     37428\n",
      "           1       0.47      0.70      0.56      2476\n",
      "\n",
      "    accuracy                           0.93     39904\n",
      "   macro avg       0.73      0.82      0.76     39904\n",
      "weighted avg       0.95      0.93      0.94     39904\n",
      "\n",
      "Cross-validation with RandomForestClassifier and SMOTEENN: 333.80 seconds\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.82919209, 0.82555978, 0.82136833, 0.81581869, 0.82323388])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# SMOTE and Edited Nearest Neighbors (SMOTEENN)\n",
    "time_cross_val_score(X, y, RandomForestClassifier(random_state=42), SMOTEENN(random_state=42))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e2a9ae5-d417-4261-b858-29d4c2a636f9",
   "metadata": {},
   "source": [
    "## Evaluating a Model\n",
    "\n",
    "The RandomForestClassifier is relatively robust, as it isn't significantly affected by how features are encoded or scaled, and it shows some resistance to irrelevant columns as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "398bccdf-f36a-4e16-9cc5-00fa12b32c73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit with training data.\n",
    "model = RandomForestClassifier(random_state=42)\n",
    "model.fit(X, y);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a0c9a661-ec4f-489b-ac72-0e6ae8c6dc5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict with testing data.\n",
    "predictions = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "58931c16-9b31-4160-8c12-c52a9a9dce93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.99      0.98     93576\n",
      "           1       0.74      0.45      0.56      6186\n",
      "\n",
      "    accuracy                           0.96     99762\n",
      "   macro avg       0.85      0.72      0.77     99762\n",
      "weighted avg       0.95      0.96      0.95     99762\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# The correct labels should come first. I had flipped these before giving me bad looking results.\n",
    "print(classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "277dc7d4-79c4-44f8-b3c1-42e9089d3da2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7191846664240384\n"
     ]
    }
   ],
   "source": [
    "# Reversed these by mistake.\n",
    "print(balanced_accuracy_score(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "84877a97-901b-4146-9688-b90feb6f510d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9394319529856986"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Measures the model's ability to distinguish between classes.\n",
    "roc_auc_score(y_test, model.predict_proba(X_test)[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "037e2cc0-ebdf-4404-8bb7-d295b3b02f4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.650550455095561"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision, recall, thresholds = precision_recall_curve(y_test, model.predict_proba(X_test)[:, 1])\n",
    "\n",
    "# Measures the model's ability to balance precision and recall across different thresholds.\n",
    "auc(recall, precision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "9f76e89e-7a1b-4b7f-bad1-bd14c9804d61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Threshold: 0.10 | Precision: 0.3255 | Recall: 0.8603\n",
      "Threshold: 0.20 | Precision: 0.4539 | Recall: 0.7544\n",
      "Threshold: 0.30 | Precision: 0.5681 | Recall: 0.6387\n",
      "Threshold: 0.40 | Precision: 0.6547 | Recall: 0.5521\n",
      "Threshold: 0.50 | Precision: 0.7286 | Recall: 0.4562\n",
      "Threshold: 0.60 | Precision: 0.8001 | Recall: 0.3526\n",
      "Threshold: 0.70 | Precision: 0.8652 | Recall: 0.2593\n",
      "Threshold: 0.80 | Precision: 0.9257 | Recall: 0.1693\n",
      "Threshold: 0.90 | Precision: 0.9566 | Recall: 0.0784\n"
     ]
    }
   ],
   "source": [
    "predict_probabilities = model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "for threshold in np.arange(0.1, 1.0, 0.1):\n",
    "    predictions = (predict_probabilities >= threshold).astype(int)\n",
    "\n",
    "    # Calculate precision and recall.\n",
    "    precision = precision_score(y_test, predictions)\n",
    "    recall = recall_score(y_test, predictions)\n",
    "\n",
    "    print(f'Threshold: {threshold:.2f} | Precision: {precision:.4f} | Recall: {recall:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ad52eb3-2c1f-41b7-9d90-3e1d55b1df02",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
