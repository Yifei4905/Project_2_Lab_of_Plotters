{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d46f5412-ecfd-4914-9d15-4d8e29989f26",
   "metadata": {},
   "source": [
    "# Loading the Census Income (KDD) Dataset\n",
    "The `.names` file is a convention used by the UCI Machine Learning Repository to provide essential metadata about the datasets they host."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e8e5a91d-168e-423b-8ad0-b9e82868bb04",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "# Importing necessary objects for data manipulation and analysis.\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.metrics import classification_report, balanced_accuracy_score, roc_auc_score, precision_recall_curve, auc, precision_score, recall_score\n",
    "from sklearn.preprocessing import OneHotEncoder, OrdinalEncoder, LabelEncoder, StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from imblearn.under_sampling import ClusterCentroids\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.combine import SMOTEENN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4a54b174-efd4-4ca5-a511-5ada4c52a167",
   "metadata": {},
   "outputs": [],
   "source": [
    "# It's easier to extract useful infomration about column names and distinct values from the .names file then to write it out.\n",
    "def parse_names():\n",
    "    \"\"\"\n",
    "    Parses the .names file from the Census-Income (KDD) dataset to extract information about the variables.\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary where each key is a variable name, and the value describes the variable as either 'continuous' or 'nominal'.\n",
    "              For nominal variables, it includes the distinct values found in the dataset.\n",
    "    \"\"\"\n",
    "\n",
    "    result = {}\n",
    "\n",
    "    # The .names file doesn't follow a strict format.\n",
    "    with open('../data/census/census-income.names', 'r') as file:\n",
    "        text = file.read()\n",
    "\n",
    "    # Just take lines that define attributes.\n",
    "    etch = list(filter(lambda x: not (x.startswith('|') or x.startswith('-') or x.strip() == ''), text.splitlines()))\n",
    "    for line in etch:\n",
    "        key, value = map(lambda x: x.rstrip(\".\").strip(), line.split(':'))\n",
    "\n",
    "        if value == \"continuous\":\n",
    "            result[key] = {\"type\": \"continuous\"}\n",
    "        else:\n",
    "            values = list(map(lambda x: x.strip(), value.split(\",\")))\n",
    "\n",
    "            # Try converting to an integer.\n",
    "            try:\n",
    "                values = list(map(int, values))\n",
    "            except:\n",
    "                pass\n",
    "            result[key] = {\"type\": \"nominal\", \"values\": values}\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c4401fdd-9c51-4576-ba18-11a6f92cb615",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function parse_names in module __main__:\n",
      "\n",
      "parse_names()\n",
      "    Parses the .names file from the Census-Income (KDD) dataset to extract information about the variables.\n",
      "    \n",
      "    Returns:\n",
      "        dict: A dictionary where each key is a variable name, and the value describes the variable as either 'continuous' or 'nominal'.\n",
      "              For nominal variables, it includes the distinct values found in the dataset.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Invoke the built-in help system.\n",
    "help(parse_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "546ef9db-c336-44a3-bacb-ec62a4ce2a4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A 'codebook' is just something to help with understanding a dataset.\n",
    "codebook = parse_names()\n",
    "\n",
    "# The target is the last column in the dataset.\n",
    "column_names = list(codebook.keys()) + [\"income\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8338ae15-203e-48e8-b87e-ded08743915b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(199523, 42)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = pd.read_csv('../data/census/census-income.data', names=column_names, index_col=False)\n",
    "train_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "89f34925-f411-43a6-b92c-9e9cb5ef33ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(99762, 42)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df = pd.read_csv('../data/census/census-income.test', names=column_names, index_col=False)\n",
    "test_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "792c5bb2-c13e-4fab-abb5-f0934d02d043",
   "metadata": {},
   "source": [
    "# Exploring the Dataset\n",
    "\n",
    "Pandas preserves spaces that are in the dataset, these spaces aren't important and can be removed while exploring.\n",
    "\n",
    "Missing values show up in the dataset as '?'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8297f75b-3b64-4023-b2e0-4a5af2a3635c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 199523 entries, 0 to 199522\n",
      "Data columns (total 42 columns):\n",
      " #   Column                                      Non-Null Count   Dtype  \n",
      "---  ------                                      --------------   -----  \n",
      " 0   age                                         199523 non-null  int64  \n",
      " 1   class of worker                             199523 non-null  object \n",
      " 2   detailed industry recode                    199523 non-null  int64  \n",
      " 3   detailed occupation recode                  199523 non-null  int64  \n",
      " 4   education                                   199523 non-null  object \n",
      " 5   wage per hour                               199523 non-null  int64  \n",
      " 6   enroll in edu inst last wk                  199523 non-null  object \n",
      " 7   marital stat                                199523 non-null  object \n",
      " 8   major industry code                         199523 non-null  object \n",
      " 9   major occupation code                       199523 non-null  object \n",
      " 10  race                                        199523 non-null  object \n",
      " 11  hispanic origin                             199523 non-null  object \n",
      " 12  sex                                         199523 non-null  object \n",
      " 13  member of a labor union                     199523 non-null  object \n",
      " 14  reason for unemployment                     199523 non-null  object \n",
      " 15  full or part time employment stat           199523 non-null  object \n",
      " 16  capital gains                               199523 non-null  int64  \n",
      " 17  capital losses                              199523 non-null  int64  \n",
      " 18  dividends from stocks                       199523 non-null  int64  \n",
      " 19  tax filer stat                              199523 non-null  object \n",
      " 20  region of previous residence                199523 non-null  object \n",
      " 21  state of previous residence                 198815 non-null  object \n",
      " 22  detailed household and family stat          199523 non-null  object \n",
      " 23  detailed household summary in household     199523 non-null  object \n",
      " 24  instance weight                             199523 non-null  float64\n",
      " 25  migration code-change in msa                99827 non-null   object \n",
      " 26  migration code-change in reg                99827 non-null   object \n",
      " 27  migration code-move within reg              99827 non-null   object \n",
      " 28  live in this house 1 year ago               199523 non-null  object \n",
      " 29  migration prev res in sunbelt               99827 non-null   object \n",
      " 30  num persons worked for employer             199523 non-null  int64  \n",
      " 31  family members under 18                     199523 non-null  object \n",
      " 32  country of birth father                     192810 non-null  object \n",
      " 33  country of birth mother                     193404 non-null  object \n",
      " 34  country of birth self                       196130 non-null  object \n",
      " 35  citizenship                                 199523 non-null  object \n",
      " 36  own business or self employed               199523 non-null  int64  \n",
      " 37  fill inc questionnaire for veteran's admin  199523 non-null  object \n",
      " 38  veterans benefits                           199523 non-null  int64  \n",
      " 39  weeks worked in year                        199523 non-null  int64  \n",
      " 40  year                                        199523 non-null  int64  \n",
      " 41  income                                      199523 non-null  object \n",
      "dtypes: float64(1), int64(12), object(29)\n",
      "memory usage: 63.9+ MB\n"
     ]
    }
   ],
   "source": [
    "df = train_df.apply(lambda x: x.str.strip() if x.dtype == \"object\" else x)\n",
    "\n",
    "# You can check the column names, missing values, and data type.\n",
    "df.replace('?', None).info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8b136352-621c-404b-857e-f8034bafcf36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "state of previous residence: {'?'}\n",
      "migration code-change in msa: {'?'}\n",
      "migration code-change in reg: {'?'}\n",
      "migration code-move within reg: {'?'}\n",
      "migration prev res in sunbelt: {'?'}\n",
      "country of birth father: {'?'}\n",
      "country of birth mother: {'?'}\n",
      "country of birth self: {'?'}\n"
     ]
    }
   ],
   "source": [
    "# Find values that aren't listed in .names.\n",
    "def display_unexpected_values(df, codebook):\n",
    "    for key, value in codebook.items():\n",
    "        if value[\"type\"] == \"continuous\":\n",
    "            continue\n",
    "\n",
    "        expected_values = set(value[\"values\"])\n",
    "        actual_values = set(df[key].unique())\n",
    "        unexpected_values = actual_values - expected_values\n",
    "\n",
    "        if unexpected_values:\n",
    "            print(f\"{key}: {unexpected_values}\")\n",
    "\n",
    "# The .names file doens't talk about '?' as a posible value for the nominals which is why it's showing up.\n",
    "display_unexpected_values(df, codebook)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "948e062b-752d-4881-96d8-906c88d536c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "state of previous residence: 0.35% missing\n",
      "migration code-change in msa: 49.97% missing\n",
      "migration code-change in reg: 49.97% missing\n",
      "migration code-move within reg: 49.97% missing\n",
      "migration prev res in sunbelt: 49.97% missing\n",
      "country of birth father: 3.36% missing\n",
      "country of birth mother: 3.07% missing\n",
      "country of birth self: 1.70% missing\n"
     ]
    }
   ],
   "source": [
    "def calculate_missingness(df):\n",
    "    for column in df.select_dtypes(include=['object']):\n",
    "        missing_count = (df[column].str.strip() == \"?\").sum()\n",
    "        total_count = len(df[column])\n",
    "        missing_percentage = (missing_count / total_count) * 100\n",
    "        if missing_count > 0:\n",
    "            print(f\"{column}: {missing_percentage:.2f}% missing\")\n",
    "\n",
    "# Computes the percentage of missing values represented by '?' for string columns in the dataset.\n",
    "calculate_missingness(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "096678e2-345f-4810-b089-5da1ba8cc125",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>min</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>age</th>\n",
       "      <td>0.0</td>\n",
       "      <td>90.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wage per hour</th>\n",
       "      <td>0.0</td>\n",
       "      <td>9999.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>capital gains</th>\n",
       "      <td>0.0</td>\n",
       "      <td>99999.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>capital losses</th>\n",
       "      <td>0.0</td>\n",
       "      <td>4608.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dividends from stocks</th>\n",
       "      <td>0.0</td>\n",
       "      <td>99999.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>num persons worked for employer</th>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weeks worked in year</th>\n",
       "      <td>0.0</td>\n",
       "      <td>52.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 min      max\n",
       "age                              0.0     90.0\n",
       "wage per hour                    0.0   9999.0\n",
       "capital gains                    0.0  99999.0\n",
       "capital losses                   0.0   4608.0\n",
       "dividends from stocks            0.0  99999.0\n",
       "num persons worked for employer  0.0      6.0\n",
       "weeks worked in year             0.0     52.0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's only look at columns that actually represent numeric data.\n",
    "continuous = list(filter(lambda x: codebook[x][\"type\"] == \"continuous\" and x != \"instance weight\", codebook.keys()))\n",
    "\n",
    "# Some of these values might be capped.\n",
    "df[continuous].describe().T[[\"min\", \"max\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fda99181-7b28-4347-937d-14feb178d9a2",
   "metadata": {},
   "source": [
    "# Binary Classification Task\n",
    "\n",
    "The **Census-Income (KDD)** dataset is derived from the **1994 and 1995 Current Population Surveys (CPS)** conducted by the U.S. Census Bureau.\n",
    "\n",
    "It includes **199,523 training instances** and **99,762 test instances**.\n",
    "\n",
    "The goal is to predict the income level based on the data provided in each row. Incomes have been binned at the $50K level to create a binary classification problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ae2ba05e-7a42-4323-b030-516d6750633c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of categorical columns.\n",
    "nominal = list(filter(lambda x: codebook[x][\"type\"] == \"nominal\", codebook.keys()))\n",
    "\n",
    "# List of numerical columns.\n",
    "continuous = list(filter(lambda x: codebook[x][\"type\"] == \"continuous\", codebook.keys()))\n",
    "\n",
    "# Ignore 'instance weight'.\n",
    "continuous.remove(\"instance weight\")\n",
    "\n",
    "# The 'instance weight' column happens to make the RandomForestClassifier more accurate.\n",
    "# The dataset feels like a distribution problem to me instead of a prediction problem so I'd tend to use any columns that help with modeling the distribution.\n",
    "# The .names file suggested to not use it... I don't even think there are real realtionships to learn in this data though.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33b4158a-4f38-458a-a982-af99d8719d7b",
   "metadata": {},
   "source": [
    "## Encoding Categorical Features\n",
    "\n",
    "The way features are encoded for this dataset doesn't seem to make much difference in the modeling.\n",
    "\n",
    "Most columns do not have a natural ordering and should use One-Hot encoding for best performance!\n",
    "\n",
    "The `OneHotEncoder` makes things substantially slower though, so I need to suffer through that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "d734a56d-71f5-4bbe-8f6e-25809fcde60e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# education_order = [\n",
    "#     ' Children',\n",
    "#     ' Less than 1st grade',\n",
    "#     ' 1st 2nd 3rd or 4th grade',\n",
    "#     ' 5th or 6th grade',\n",
    "#     ' 7th and 8th grade',\n",
    "#     ' 9th grade',\n",
    "#     ' 10th grade',\n",
    "#     ' 11th grade',\n",
    "#     ' 12th grade no diploma',\n",
    "#     ' High school graduate',\n",
    "#     ' Some college but no degree',\n",
    "#     ' Associates degree-occup /vocational',\n",
    "#     ' Associates degree-academic program',\n",
    "#     ' Bachelors degree(BA AB BS)',\n",
    "#     ' Masters degree(MA MS MEng MEd MSW MBA)',\n",
    "#     ' Doctorate degree(PhD EdD)',\n",
    "#     ' Prof school degree (MD DDS DVM LLB JD)'\n",
    "# ]\n",
    "\n",
    "# ordinal_encoder = OrdinalEncoder(categories=[education_order])\n",
    "# ordinal_encoder.fit(train_df[['education']])\n",
    "\n",
    "# education_df = pd.DataFrame(ordinal_encoder.transform(train_df[['education']]), columns=['education'])\n",
    "# education_test_df = pd.DataFrame(ordinal_encoder.transform(test_df[['education']]), columns=['education'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3c0cdbcd-d4d7-42ae-b7e6-98543c857800",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode categorical features.\n",
    "encoder = OneHotEncoder(drop='first', sparse_output=False)\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "# Fit the encoders to the training data.\n",
    "encoder.fit(train_df[nominal])\n",
    "label_encoder.fit(train_df[\"income\"])\n",
    "\n",
    "# Names for the encoded features.\n",
    "feature_names = encoder.get_feature_names_out(nominal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cf1ff958-85d3-45b1-a4ef-e4f51fbaa47f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([' - 50000.', ' 50000+.'], dtype=object)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The unique values are sorted in lexicographical order.\n",
    "label_encoder.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "428fd20d-7bff-4e33-985f-36b9bce7d562",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode training data.\n",
    "X = pd.concat([pd.DataFrame(encoder.transform(train_df[nominal]), columns=feature_names), train_df[continuous]], axis=1)\n",
    "y = label_encoder.transform(train_df[\"income\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "78bc7b0a-6ecf-4239-b940-bf516dde64be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode testing data.\n",
    "X_test = pd.concat([pd.DataFrame(encoder.transform(test_df[nominal]), columns=feature_names), test_df[continuous]], axis=1)\n",
    "y_test = label_encoder.transform(test_df[\"income\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9597792d-52ae-4625-b1dd-83f1da41ac7d",
   "metadata": {},
   "source": [
    "## Scaling Features\n",
    "\n",
    "You don't need to scale the categorical columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "d25d24a7-3977-4cf7-84d6-18a49e1ed775",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit a standard scaler to training data.\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X[continuous])\n",
    "\n",
    "# Transform the training data.\n",
    "X[continuous] = scaler.transform(X[continuous])\n",
    "\n",
    "# Transform the testing data.\n",
    "X_test[continuous] = scaler.transform(X_test[continuous])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e2a9ae5-d417-4261-b858-29d4c2a636f9",
   "metadata": {},
   "source": [
    "## Evaluating a Model\n",
    "\n",
    "The RandomForestClassifier is relatively robust, as it isn't significantly affected by how features are encoded or scaled, and it shows some resistance to irrelevant columns as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "398bccdf-f36a-4e16-9cc5-00fa12b32c73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit with training data.\n",
    "model = RandomForestClassifier(random_state=42)\n",
    "model.fit(X, y);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "a0c9a661-ec4f-489b-ac72-0e6ae8c6dc5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict with testing data.\n",
    "predictions = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "58931c16-9b31-4160-8c12-c52a9a9dce93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.99      0.98     93576\n",
      "           1       0.73      0.40      0.52      6186\n",
      "\n",
      "    accuracy                           0.95     99762\n",
      "   macro avg       0.85      0.70      0.75     99762\n",
      "weighted avg       0.95      0.95      0.95     99762\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# The correct labels should come first. I had flipped these before giving me bad looking results.\n",
    "print(classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "277dc7d4-79c4-44f8-b3c1-42e9089d3da2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8468403146414989\n"
     ]
    }
   ],
   "source": [
    "print(balanced_accuracy_score(predictions, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "84877a97-901b-4146-9688-b90feb6f510d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9367346843267779"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Measures the model's ability to distinguish between classes.\n",
    "roc_auc_score(y_test, model.predict_proba(X_test)[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "037e2cc0-ebdf-4404-8bb7-d295b3b02f4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6246328289239371"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision, recall, thresholds = precision_recall_curve(y_test, model.predict_proba(X_test)[:, 1])\n",
    "\n",
    "# Measures the model's ability to balance precision and recall across different thresholds.\n",
    "auc(recall, precision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9f76e89e-7a1b-4b7f-bad1-bd14c9804d61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Threshold: 0.10 | Precision: 0.3222 | Recall: 0.8590\n",
      "Threshold: 0.20 | Precision: 0.4556 | Recall: 0.7449\n",
      "Threshold: 0.30 | Precision: 0.5699 | Recall: 0.6107\n",
      "Threshold: 0.40 | Precision: 0.6472 | Recall: 0.5124\n",
      "Threshold: 0.50 | Precision: 0.7298 | Recall: 0.4100\n",
      "Threshold: 0.60 | Precision: 0.8055 | Recall: 0.2913\n",
      "Threshold: 0.70 | Precision: 0.8670 | Recall: 0.1866\n",
      "Threshold: 0.80 | Precision: 0.9103 | Recall: 0.1115\n",
      "Threshold: 0.90 | Precision: 0.9450 | Recall: 0.0445\n"
     ]
    }
   ],
   "source": [
    "predict_probabilities = model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "for threshold in np.arange(0.1, 1.0, 0.1):\n",
    "    predictions = (predict_probabilities >= threshold).astype(int)\n",
    "\n",
    "    # Calculate precision and recall.\n",
    "    precision = precision_score(y_test, predictions)\n",
    "    recall = recall_score(y_test, predictions)\n",
    "\n",
    "    print(f'Threshold: {threshold:.2f} | Precision: {precision:.4f} | Recall: {recall:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf9f4cd6-6425-47ef-855a-b637098c93c4",
   "metadata": {},
   "source": [
    "## Dealing With Class Imbalance\n",
    "\n",
    "Oversampling can improve the reseults on the minority class slightly and it doesn't take a long time to run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7a0d3db0-0477-4ca0-91cf-ea74a90dd093",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_class_imbalance(target):\n",
    "    class_0_count = np.count_nonzero(target == 0)\n",
    "    class_1_count = np.count_nonzero(target == 1)\n",
    "    total_count = len(target)\n",
    "\n",
    "    # Calculate the percentages.\n",
    "    class_0_percentage = (class_0_count / total_count) * 100\n",
    "    class_1_percentage = (class_1_count / total_count) * 100\n",
    "\n",
    "    print(f\"Class 0: {class_0_count} instances, {class_0_percentage}% of the total\")\n",
    "    print(f\"Class 1: {class_1_count} instances, {class_1_percentage}% of the total\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5dd4c1ef-ac24-44b2-8cdf-e1df493c0045",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class 0: 93576 instances, 93.7992421964275% of the total\n",
      "Class 1: 6186 instances, 6.200757803572503% of the total\n"
     ]
    }
   ],
   "source": [
    "display_class_imbalance(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "53d3188d-8fe5-45cc-ab7d-ea58d0bc5c19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resampling takes a while this function let's me check how long.\n",
    "def resample(X, y, sampler_class, random_state=42):\n",
    "    start_time = time.time()\n",
    "    sampler = sampler_class(random_state=random_state)\n",
    "    X_resampled, y_resampled = sampler.fit_resample(X, y)\n",
    "    end_time = time.time()\n",
    "    elapsed_time = end_time - start_time\n",
    "    print(f\"{elapsed_time:.2f} seconds\")\n",
    "    return X_resampled, y_resampled"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "696efaa2-c542-4269-b6ff-3d087aa64ab3",
   "metadata": {},
   "source": [
    "#### Random Oversampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "06388f19-b9cf-420f-a870-971f63bbbc48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.62 seconds\n"
     ]
    }
   ],
   "source": [
    "X_ros, y_ros = resample(X, y, RandomOverSampler)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f8af3ca-4c7c-4acd-a16c-7f059151b508",
   "metadata": {},
   "source": [
    "#### Random Undersampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c4b5fb6a-2d9d-4de4-9c61-539451c5dff5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.06 seconds\n"
     ]
    }
   ],
   "source": [
    "X_rus, y_rus = resample(X, y, RandomUnderSampler)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08c7ef5d-bf62-4b62-b70c-b54a5fe2a0fe",
   "metadata": {},
   "source": [
    "#### Cluster Centroids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "0be91621-0268-4de2-a0ed-55c6b331eee1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "627.34 seconds\n"
     ]
    }
   ],
   "source": [
    "X_cc, y_cc = resample(X, y, ClusterCentroids)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a860ffa-904e-4447-8505-f97e438399f4",
   "metadata": {},
   "source": [
    "#### Synthetic Minority Oversampling Technique (SMOTE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "45117c0c-3d64-444d-a4b1-dd3c4864b0f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.49 seconds\n"
     ]
    }
   ],
   "source": [
    "X_smote, y_smote = resample(X, y, SMOTE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65599e34-b466-44a1-84fa-aeeee3f3c04a",
   "metadata": {},
   "source": [
    "#### SMOTE and Edited Nearest Neighbors (SMOTEENN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "40f46010-fb0f-49d5-bf3e-b9fa2068b185",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "370.05 seconds\n"
     ]
    }
   ],
   "source": [
    "X_smoteenn, y_smoteenn = resample(X, y, SMOTEENN)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06c50631-036f-4875-afcd-4486638b5fcb",
   "metadata": {},
   "source": [
    "### Building and Evaluating Models on Resampled Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "44587acf-e2cb-448a-a3a7-29b4c34a6a7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_ros = RandomForestClassifier(random_state=42)\n",
    "model_ros.fit(X_ros, y_ros);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "6799c2d2-3837-4896-a588-341a50d66d2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_rus = RandomForestClassifier(random_state=42)\n",
    "model_rus.fit(X_rus, y_rus);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "d11aa71a-b0d4-47ca-bcd2-098fac60a34c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_cc = RandomForestClassifier(random_state=42)\n",
    "model_cc.fit(X_cc, y_cc);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "518b4a4f-e00f-45db-a55b-7c06e004bb12",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_smote = RandomForestClassifier(random_state=42)\n",
    "model_smote.fit(X_smote, y_smote);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "6ed06b56-ae7c-4262-be26-36dbdd9d6bbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_smoteenn = RandomForestClassifier(random_state=42)\n",
    "model_smoteenn.fit(X_smoteenn, y_smoteenn);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "f7b754fb-f54a-43f8-9aba-0c73f113723f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Oversampling: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.99      0.91     79746\n",
      "           1       0.90      0.28      0.42     20016\n",
      "\n",
      "    accuracy                           0.85     99762\n",
      "   macro avg       0.87      0.63      0.67     99762\n",
      "weighted avg       0.86      0.85      0.81     99762\n",
      "\n",
      "Balanced Accuracy: 0.871470479925258\n",
      "\n",
      "Random Undersampling: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.97      0.97     94825\n",
      "           1       0.50      0.62      0.55      4937\n",
      "\n",
      "    accuracy                           0.95     99762\n",
      "   macro avg       0.74      0.79      0.76     99762\n",
      "weighted avg       0.96      0.95      0.95     99762\n",
      "\n",
      "Balanced Accuracy: 0.7380789440319241\n",
      "\n",
      "Cluster Centroids: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.49      1.00      0.66     45866\n",
      "           1       0.98      0.11      0.20     53896\n",
      "\n",
      "    accuracy                           0.52     99762\n",
      "   macro avg       0.74      0.56      0.43     99762\n",
      "weighted avg       0.76      0.52      0.41     99762\n",
      "\n",
      "Balanced Accuracy: 0.7356808922131542\n",
      "\n",
      "SMOTE: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.97      0.97     94921\n",
      "           1       0.48      0.62      0.54      4841\n",
      "\n",
      "    accuracy                           0.95     99762\n",
      "   macro avg       0.73      0.79      0.76     99762\n",
      "weighted avg       0.96      0.95      0.95     99762\n",
      "\n",
      "Balanced Accuracy: 0.7324737603389563\n",
      "\n",
      "SMOTEENN: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.98      0.96     89979\n",
      "           1       0.70      0.44      0.54      9783\n",
      "\n",
      "    accuracy                           0.93     99762\n",
      "   macro avg       0.82      0.71      0.75     99762\n",
      "weighted avg       0.92      0.93      0.92     99762\n",
      "\n",
      "Balanced Accuracy: 0.8214502864811433\n",
      "\n"
     ]
    }
   ],
   "source": [
    "models = [\n",
    "    (model_rus, \"Random Oversampling\"),\n",
    "    (model_ros, \"Random Undersampling\"),\n",
    "    (model_cc, \"Cluster Centroids\"),\n",
    "    (model_smote, \"SMOTE\"),\n",
    "    (model_smoteenn, \"SMOTEENN\")\n",
    "]\n",
    "\n",
    "for model, text in models:\n",
    "    print(f\"{text}: \")\n",
    "    predictions = model.predict(X_test)\n",
    "    print(classification_report(predictions, y_test))\n",
    "    print(f\"Balanced Accuracy: {balanced_accuracy_score(y_test, predictions)}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6930d0b5-a38a-4a60-8b60-687a430ceba4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
